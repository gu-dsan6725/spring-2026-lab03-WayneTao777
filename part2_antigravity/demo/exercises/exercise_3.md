# Exercise 3: End-to-End with Manager View

## Objective

Use Google Antigravity's Manager view to orchestrate the full ML pipeline -- from data
exploration through model training to evaluation -- using multiple agents working across
workspaces.

## Background

Google Antigravity provides two primary views:

- **Editor view**: A traditional IDE interface with an agent sidebar for direct coding
  assistance (similar to tools like Cursor or GitHub Copilot).

- **Manager view**: A control center for orchestrating multiple agents working in parallel
  across workspaces. Agents execute autonomously and produce "artifacts" -- verifiable
  deliverables like task lists, implementation plans, screenshots, and browser recordings --
  rather than raw tool calls.

The Manager view is Antigravity's approach to task decomposition. In Claude Code, you
achieve similar decomposition using subagents (Explore, Plan, Bash, general-purpose).
In Antigravity, you spawn agents from the Manager view and monitor their progress through
artifacts.

Antigravity also offers terminal execution policies that control agent autonomy:
- **Off**: Commands never auto-execute; the agent proposes and you approve each step
- **Auto**: The agent decides which commands to auto-execute based on risk level
- **Turbo**: Commands auto-execute unless explicitly denied

Reference:
- [Google Developers Blog: Antigravity](https://developers.googleblog.com/build-with-google-antigravity-our-new-agentic-development-platform/)

### Hooks Gap

Unlike Claude Code, Google Antigravity does not currently have native hook-based triggers
that auto-run commands at specific lifecycle points (such as after a file is written or
before a commit). To achieve similar automation, you would use:

- **Standard git pre-commit hooks** via the [pre-commit](https://pre-commit.com/) framework
- **Workflow steps** that explicitly include quality checks
- **Rules** that instruct the agent to always run linting after writing code

This is a meaningful difference: Claude Code hooks guarantee execution regardless of the
agent's behavior, while Antigravity rules are instructions the agent should follow but
are not enforced programmatically.

## Requirements

### 1. Set Up Pre-Commit Hooks (Replacing Claude Code Hooks)

Since Antigravity lacks native hooks, set up the `pre-commit` framework:

Create `.pre-commit-config.yaml`:
```yaml
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.8.0
    hooks:
      - id: ruff
        args: [--fix]
      - id: ruff-format
```

Install with:
```bash
uv add --dev pre-commit
uv run pre-commit install
```

### 2. Create an Agent Plan

In Antigravity's Editor view (or Manager view), ask the agent to create an implementation
plan for the full pipeline:

```
Create a detailed plan for building a California Housing price prediction pipeline.
The plan should cover: data loading, EDA, feature engineering, model training with
XGBoost, and evaluation. Write the plan to plan.md.
```

Review the plan and request at least two modifications.

### 3. Execute with Manager View

From the Manager view, create separate agent tasks:

- **Agent 1: Data Preparation** - Load the dataset, run EDA, perform feature engineering
- **Agent 2: Model Training** - Train XGBoost model using prepared data
- **Agent 3: Evaluation** - Evaluate the model and generate the report

Use the "Auto" execution policy so the agent pauses for your review on higher-risk operations.

### 4. Review Artifacts

For each agent, verify:
- The implementation plan artifact shows clear steps
- The code follows the project rules (`.agent/rules/code-style-guide.md`)
- Pre-commit hooks catch any style issues on commit

## Deliverables

1. `.pre-commit-config.yaml` file
2. `plan.md` -- the implementation plan created by the agent
3. Python files generated by each agent
4. `output/` directory with all artifacts (plots, model, report)
5. A comparison writeup (300-500 words) answering:
   - How does Antigravity's Manager view compare to Claude Code's subagents?
   - What are the advantages and limitations of each approach?
   - How do Claude Code hooks compare to using pre-commit + Antigravity rules?
   - Which tool would you prefer for a data science project and why?

## Grading Criteria

- Pre-commit hooks are correctly configured and functional
- Plan demonstrates clear task decomposition
- Each agent task is well-scoped and produces expected artifacts
- Comparison writeup shows understanding of both tools' strengths and weaknesses
- Generated code follows project rules
